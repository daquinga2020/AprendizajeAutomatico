{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Setup a Virtual Display\n",
        "To generate a replay video of agent and environment."
      ],
      "metadata": {
        "id": "1JZkkkRezF2h"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4jLiaLlkqeK7"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install pyglet==1.5.1\n",
        "!apt install python-opengl\n",
        "!apt install ffmpeg\n",
        "!apt install xvfb\n",
        "!pip3 install pyvirtualdisplay\n",
        "\n",
        "# Virtual display\n",
        "from pyvirtualdisplay import Display\n",
        "\n",
        "virtual_display = Display(visible=0, size=(1400, 900))\n",
        "virtual_display.start()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install dependencies"
      ],
      "metadata": {
        "id": "YA8eccSjzTkm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install gym==0.24\n",
        "!pip install pygame\n",
        "!pip install numpy\n",
        "\n",
        "!pip install imageio imageio_ffmpeg"
      ],
      "metadata": {
        "id": "qy__wzWWq1Ip"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import the packages"
      ],
      "metadata": {
        "id": "_PapFtBBzW3G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import gym\n",
        "import random\n",
        "import imageio\n",
        "from tqdm.notebook import trange"
      ],
      "metadata": {
        "id": "PWkA0eXLq52V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Frozen Lake"
      ],
      "metadata": {
        "id": "868LWxur0OGI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the FrozenLake-v1 environment using 4x4 map and non-slippery version\n",
        "env = gym.make(\"FrozenLake-v1\",map_name=\"4x4\",is_slippery=False)"
      ],
      "metadata": {
        "id": "Ho0clcOHrBlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Understanding the FrozenLake environment"
      ],
      "metadata": {
        "id": "jFwhmxg80WkH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"_____OBSERVATION SPACE_____ \\n\")\n",
        "print(\"Observation Space\", env.observation_space)\n",
        "print(\"Sample observation\", env.observation_space.sample()) # Get a random observation"
      ],
      "metadata": {
        "id": "rQtUaOEJrDVf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n _____ACTION SPACE_____ \\n\")\n",
        "print(\"Action Space Shape\", env.action_space.n)\n",
        "print(\"Action Space Sample\", env.action_space.sample()) # Take a random action"
      ],
      "metadata": {
        "id": "7fE_JTjGrF-B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "map_description = [[str(cell, 'utf-8') for cell in row] for row in env.desc]\n",
        "\n",
        "print(\"Enviroment map:\")\n",
        "for row in map_description:\n",
        "    print(\"\".join(row))"
      ],
      "metadata": {
        "id": "bEcADC4e8-5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create and Initialize the Q-table"
      ],
      "metadata": {
        "id": "badxmLJg0i6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "state_space = env.observation_space.n\n",
        "print(\"There are \", state_space, \" possible states\")\n",
        "\n",
        "action_space = env.action_space.n\n",
        "print(\"There are \", action_space, \" possible actions\")"
      ],
      "metadata": {
        "id": "2m0z54AfrJVj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_q_table(state_space, action_space):\n",
        "  Qtable = np.zeros((state_space, action_space))\n",
        "  return Qtable"
      ],
      "metadata": {
        "id": "rCddoOXM3UQH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Qtable_frozenlake = initialize_q_table(state_space, action_space)"
      ],
      "metadata": {
        "id": "9YfvrqRt3jdR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the epsilon-greedy policy"
      ],
      "metadata": {
        "id": "lFeeieaA0mQ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def epsilon_greedy_policy(Qtable, state, epsilon):\n",
        "  random_int = random.uniform(0,1)\n",
        "  if random_int > epsilon:\n",
        "    action = np.argmax(Qtable[state])\n",
        "  else:\n",
        "    action = env.action_space.sample()\n",
        "\n",
        "  return action"
      ],
      "metadata": {
        "id": "Pe3nPqOQrYXi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the greedy policy"
      ],
      "metadata": {
        "id": "TMc7hclu0uI1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def greedy_policy(Qtable, state):\n",
        "  action = np.argmax(Qtable[state])\n",
        "\n",
        "  return action"
      ],
      "metadata": {
        "id": "Xvh3Qj0rrbPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define the hyperparameters"
      ],
      "metadata": {
        "id": "AStP0Cwf0vjF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_training_episodes = 10000\n",
        "learning_rate = 0.7\n",
        "\n",
        "n_eval_episodes = 100\n",
        "\n",
        "env_id = \"FrozenLake-v1\"\n",
        "max_steps = 99\n",
        "gamma = 0.95\n",
        "eval_seed = []\n",
        "\n",
        "max_epsilon = 1.0\n",
        "min_epsilon = 0.05\n",
        "decay_rate = 0.0005"
      ],
      "metadata": {
        "id": "Y1tWn0tycWZ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the model"
      ],
      "metadata": {
        "id": "bL4oWIJ800M6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(n_training_episodes, min_epsilon, max_epsilon, decay_rate, env, max_steps, Qtable):\n",
        "  for episode in trange(n_training_episodes):\n",
        "    epsilon = min_epsilon + (max_epsilon - min_epsilon)*np.exp(-decay_rate*episode)\n",
        "    state = env.reset()\n",
        "    step = 0\n",
        "    done = False\n",
        "\n",
        "    for step in range(max_steps):\n",
        "      action = epsilon_greedy_policy(Qtable, state, epsilon)\n",
        "\n",
        "      new_state, reward, done, info = env.step(action)\n",
        "\n",
        "      Qtable[state][action] = Qtable[state][action] + learning_rate * (reward + gamma * np.max(Qtable[new_state]) - Qtable[state][action])\n",
        "\n",
        "      if done:\n",
        "        break\n",
        "\n",
        "      state = new_state\n",
        "  return Qtable"
      ],
      "metadata": {
        "id": "paOynXy3aoJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Qtable_frozenlake = train(n_training_episodes, min_epsilon, max_epsilon, decay_rate, env, max_steps, Qtable_frozenlake)"
      ],
      "metadata": {
        "id": "DPBxfjJdTCOH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tranined Q-Learning table"
      ],
      "metadata": {
        "id": "ZE71JB7b1BiI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Qtable_frozenlake"
      ],
      "metadata": {
        "id": "me3KBqV4rqd-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model evaluation"
      ],
      "metadata": {
        "id": "ttMwujJ31Lez"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_agent(env, max_steps, n_eval_episodes, Q, seed):\n",
        "  \"\"\"\n",
        "  Evaluate the agent for ``n_eval_episodes`` episodes and returns average reward and std of reward.\n",
        "  :param env: The evaluation environment\n",
        "  :param n_eval_episodes: Number of episode to evaluate the agent\n",
        "  :param Q: The Q-table\n",
        "  :param seed: The evaluation seed array (for taxi-v3)\n",
        "  \"\"\"\n",
        "  episode_rewards = []\n",
        "  for episode in range(n_eval_episodes):\n",
        "    if seed:\n",
        "      state = env.reset(seed=seed[episode])\n",
        "    else:\n",
        "      state = env.reset()\n",
        "    step = 0\n",
        "    done = False\n",
        "    total_rewards_ep = 0\n",
        "\n",
        "    for step in range(max_steps):\n",
        "\n",
        "      action = np.argmax(Q[state][:])\n",
        "      new_state, reward, done, info = env.step(action)\n",
        "      total_rewards_ep += reward\n",
        "\n",
        "      if done:\n",
        "        break\n",
        "      state = new_state\n",
        "    episode_rewards.append(total_rewards_ep)\n",
        "  mean_reward = np.mean(episode_rewards)\n",
        "  std_reward = np.std(episode_rewards)\n",
        "\n",
        "  return mean_reward, std_reward"
      ],
      "metadata": {
        "id": "jNl0_JO2cbkm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mean_reward, std_reward = evaluate_agent(env, max_steps, n_eval_episodes, Qtable_frozenlake, eval_seed)\n",
        "print(f\"Mean_reward={mean_reward:.2f} +/- {std_reward:.2f}\")"
      ],
      "metadata": {
        "id": "fAgB7s0HEFMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualizing the results"
      ],
      "metadata": {
        "id": "PQoX2Iyo1OyC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def record_video(env, Qtable, out_directory, fps=1):\n",
        "  images = []\n",
        "  done = False\n",
        "  state = env.reset(seed=random.randint(0,500))\n",
        "  img = env.render(mode='rgb_array')\n",
        "  images.append(img)\n",
        "  while not done:\n",
        "    action = np.argmax(Qtable[state][:])\n",
        "    state, reward, done, info = env.step(action)\n",
        "    img = env.render(mode='rgb_array')\n",
        "    images.append(img)\n",
        "  imageio.mimsave(out_directory, [np.array(img) for i, img in enumerate(images)], fps=fps)"
      ],
      "metadata": {
        "id": "-N7tJXVHr3VJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving animated file as gif with 1 frame per second"
      ],
      "metadata": {
        "id": "e-JGGxzi3V8Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "video_path=\"/content/replay.gif\"\n",
        "video_fps=1"
      ],
      "metadata": {
        "id": "qLw1MCIhsuX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "record_video(env, Qtable_frozenlake, video_path, video_fps)"
      ],
      "metadata": {
        "id": "lg3BXlFEsTCN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import Image\n",
        "Image('./replay.gif')"
      ],
      "metadata": {
        "id": "dl7O7de11kbZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}